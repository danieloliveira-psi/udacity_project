{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Investigation of Soccer Players' Performance\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "### Dataset Description \n",
    "\n",
    "I've selected the European Soccer Database to investigate, due to my passion on understanding performance.\n",
    "This database includes information related to soccer for seasons 2008 to 2016.\n",
    "I've opened the file using DB Browser, since it's a \".sqlite\" file. Within DB Browser I was able to better check the contents of the database (in \"Browse Data\"), which includes 8 tables, with the following information:\n",
    "- `Country` (mentions included countries)\n",
    "- `League` (mentions included leagues and their respective countries)\n",
    "- `Match` (info about soccer matches, of where and when they occurred, which teams and players played, players' positions in the field, scores, stats related to team performance during the game, the odds of winning, drawing or losing by 10 different providers)\n",
    "- `Player` (mentions included players, their birthday, height and weight)\n",
    "- `Player_Attributes` (info about each player in terms of their attributes, such as overall rating, potential, preferred foot, rate of attacking and defensive work, scores related to how good they are in various skills and general attributes, and when these measures were updated)\n",
    "- `Team` (mentions included teams)\n",
    "- `Team_Attributes` (info about each team like their scores in various attributes and its respective class, and when these measures were updated)\n",
    "- `sqlite_sequence` (unrelated to soccer information and unnecessary for this investigation)\n",
    "\n",
    "\n",
    "\n",
    "### Question(s) for Analysis\n",
    "\n",
    "\n",
    "Taking into account all information we have and my own curiosity, I've come up with 2 questions:\n",
    "\n",
    "1. **Is team overall age, height or weight correlated with matches' results?**\n",
    "\n",
    "This is a type of question very common in recruitment processes, because there is a lot of preconceived ideas about age in certain tasks' performance. I am curious to know if these seem to matter on a team performance, especialy in a sports context, although we are only investigating correlation and not causation.\n",
    "\n",
    "2. **Do players tend to achieve their perceived potential?**\n",
    "\n",
    "I want to know how many players were able to reach their first mentioned potential and by how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the packages I am expecting to use to answer all questions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "In order to answer my questions, I'll only need the tables `Match`, `Player` and `Player_Attributes`. For that reason, I've exported these 3 tables, with only the columns I believe to be necessary, and I'll merge them whenever necessary using python. I've used the following SQL code to do it:\n",
    "\n",
    ">SELECT *\n",
    "FROM Match\n",
    "\n",
    ">SELECT player_api_id, birthday, height, weight\n",
    "FROM Player\n",
    "\n",
    ">SELECT player_api_id, date, overall_rating, potential\n",
    "FROM Player_Attributes\n",
    "\n",
    "I downloaded the respective CSV files.\n",
    "\n",
    "### General Properties\n",
    "\n",
    "Now, let's look at the data to better understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>league_id</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>...</th>\n",
       "      <th>SJA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>GBH</th>\n",
       "      <th>GBD</th>\n",
       "      <th>GBA</th>\n",
       "      <th>BSH</th>\n",
       "      <th>BSD</th>\n",
       "      <th>BSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-17 00:00:00</td>\n",
       "      <td>492473</td>\n",
       "      <td>9987</td>\n",
       "      <td>9993</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.78</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  country_id  league_id     season  stage                 date  \\\n",
       "0   1           1          1  2008/2009      1  2008-08-17 00:00:00   \n",
       "\n",
       "   match_api_id  home_team_api_id  away_team_api_id  home_team_goal  ...  SJA  \\\n",
       "0        492473              9987              9993               1  ...  4.0   \n",
       "\n",
       "    VCH  VCD  VCA   GBH   GBD  GBA   BSH  BSD  BSA  \n",
       "0  1.65  3.4  4.5  1.78  3.25  4.0  1.73  3.4  4.2  \n",
       "\n",
       "[1 rows x 115 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and see Match information\n",
    "df_match = pd.read_csv(\"Football_Match.csv\")\n",
    "df_match.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'country_id', 'league_id', 'season', 'stage', 'date',\n",
       "       'match_api_id', 'home_team_api_id', 'away_team_api_id',\n",
       "       'home_team_goal', 'away_team_goal', 'home_player_X1',\n",
       "       'home_player_X2', 'home_player_X3', 'home_player_X4',\n",
       "       'home_player_X5', 'home_player_X6', 'home_player_X7',\n",
       "       'home_player_X8', 'home_player_X9', 'home_player_X10',\n",
       "       'home_player_X11', 'away_player_X1', 'away_player_X2',\n",
       "       'away_player_X3', 'away_player_X4', 'away_player_X5',\n",
       "       'away_player_X6', 'away_player_X7', 'away_player_X8',\n",
       "       'away_player_X9', 'away_player_X10', 'away_player_X11',\n",
       "       'home_player_Y1', 'home_player_Y2', 'home_player_Y3',\n",
       "       'home_player_Y4', 'home_player_Y5', 'home_player_Y6',\n",
       "       'home_player_Y7', 'home_player_Y8', 'home_player_Y9',\n",
       "       'home_player_Y10', 'home_player_Y11', 'away_player_Y1',\n",
       "       'away_player_Y2', 'away_player_Y3', 'away_player_Y4',\n",
       "       'away_player_Y5', 'away_player_Y6', 'away_player_Y7',\n",
       "       'away_player_Y8', 'away_player_Y9', 'away_player_Y10',\n",
       "       'away_player_Y11', 'home_player_1', 'home_player_2',\n",
       "       'home_player_3', 'home_player_4', 'home_player_5', 'home_player_6',\n",
       "       'home_player_7', 'home_player_8', 'home_player_9',\n",
       "       'home_player_10', 'home_player_11', 'away_player_1',\n",
       "       'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5',\n",
       "       'away_player_6', 'away_player_7', 'away_player_8', 'away_player_9',\n",
       "       'away_player_10', 'away_player_11', 'goal', 'shoton', 'shotoff',\n",
       "       'foulcommit', 'card', 'cross', 'corner', 'possession', 'B365H',\n",
       "       'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH',\n",
       "       'LBD', 'LBA', 'PSH', 'PSD', 'PSA', 'WHH', 'WHD', 'WHA', 'SJH',\n",
       "       'SJD', 'SJA', 'VCH', 'VCD', 'VCA', 'GBH', 'GBD', 'GBA', 'BSH',\n",
       "       'BSD', 'BSA'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See Match column names (too many columns, not able to use info())\n",
    "df_match.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_api_id</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>505942</td>\n",
       "      <td>1992-02-29 00:00:00</td>\n",
       "      <td>182.88</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_api_id             birthday  height  weight\n",
       "0         505942  1992-02-29 00:00:00  182.88     187"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and see Player information\n",
    "df_player = pd.read_csv(\"Football_Player.csv\")\n",
    "df_player.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11060 entries, 0 to 11059\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   player_api_id  11060 non-null  int64  \n",
      " 1   birthday       11060 non-null  object \n",
      " 2   height         11060 non-null  float64\n",
      " 3   weight         11060 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 345.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#See Player columns and their datatypes\n",
    "df_player.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_api_id</th>\n",
       "      <th>date</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>potential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>505942</td>\n",
       "      <td>2016-02-18 00:00:00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_api_id                 date  overall_rating  potential\n",
       "0         505942  2016-02-18 00:00:00            67.0       71.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and see Player_Attributes information\n",
    "df_playeratt = pd.read_csv(\"Football_Player_Attributes.csv\")\n",
    "df_playeratt.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183978 entries, 0 to 183977\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   player_api_id   183978 non-null  int64  \n",
      " 1   date            183978 non-null  object \n",
      " 2   overall_rating  183142 non-null  float64\n",
      " 3   potential       183142 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#See Player columns and their datatypes\n",
    "df_playeratt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I know all columns within the original tables. I won't explore them just yet, since there are too many. I'll first create tables with only the needed columns and then do Data Exploration Analysis within those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Cleaning\n",
    "\n",
    "First, let's create the dataframe we need for the first question.\n",
    "We need it to have the following columns:\n",
    "- `match_api_id`\n",
    "- `home_team`\n",
    "- `away_team`\n",
    "- `Overall_Age`\n",
    "- `Overall_Height`\n",
    "- `Overall_Weight`\n",
    "- `Win_Rate`\n",
    "- `Draw_Rate`\n",
    "- `Loss_Rate`\n",
    "\n",
    "We'll go one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I know I'll have to change datatype of birthday in Player, but I need to know the datetype of date in Match too\n",
    "df_match[\"date\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to change datatype of birthdate in Player and in date of Match\n",
    "df_player[\"birthday\"] = pd.to_datetime(df_player[\"birthday\"])\n",
    "df_match[\"date\"] = pd.to_datetime(df_match[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to know the average age. We'll get the average age of the team per match, first.\n",
    "#This list will help\n",
    "home_team=['home_player_1','home_player_2','home_player_3','home_player_4','home_player_5','home_player_6','home_player_7','home_player_8','home_player_9','home_player_10','home_player_11']\n",
    "away_team=['away_player_1','away_player_2','away_player_3','away_player_4','away_player_5','away_player_6','away_player_7','away_player_8','away_player_9','away_player_10','away_player_11']\n",
    "home_player_age=['home_player_1_age','home_player_2_age','home_player_3_age','home_player_4_age','home_player_5_age','home_player_6_age','home_player_7_age','home_player_8_age','home_player_9_age','home_player_10_age','home_player_11_age']\n",
    "away_player_age=['away_player_1_age','away_player_2_age','away_player_3_age','away_player_4_age','away_player_5_age','away_player_6_age','away_player_7_age','away_player_8_age','away_player_9_age','away_player_10_age''away_player_11_age']\n",
    "\n",
    "# Let's drop missing values on players id before we go on\n",
    "df_match.dropna(subset=home_team, inplace=True)\n",
    "df_match.dropna(subset=away_team, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21374 entries, 145 to 25978\n",
      "Data columns (total 26 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   date              21374 non-null  datetime64[ns]\n",
      " 1   match_api_id      21374 non-null  int64         \n",
      " 2   home_team_api_id  21374 non-null  int64         \n",
      " 3   away_team_api_id  21374 non-null  int64         \n",
      " 4   home_player_1     21374 non-null  float64       \n",
      " 5   home_player_2     21374 non-null  float64       \n",
      " 6   home_player_3     21374 non-null  float64       \n",
      " 7   home_player_4     21374 non-null  float64       \n",
      " 8   home_player_5     21374 non-null  float64       \n",
      " 9   home_player_6     21374 non-null  float64       \n",
      " 10  home_player_7     21374 non-null  float64       \n",
      " 11  home_player_8     21374 non-null  float64       \n",
      " 12  home_player_9     21374 non-null  float64       \n",
      " 13  home_player_10    21374 non-null  float64       \n",
      " 14  home_player_11    21374 non-null  float64       \n",
      " 15  away_player_1     21374 non-null  float64       \n",
      " 16  away_player_2     21374 non-null  float64       \n",
      " 17  away_player_3     21374 non-null  float64       \n",
      " 18  away_player_4     21374 non-null  float64       \n",
      " 19  away_player_5     21374 non-null  float64       \n",
      " 20  away_player_6     21374 non-null  float64       \n",
      " 21  away_player_7     21374 non-null  float64       \n",
      " 22  away_player_8     21374 non-null  float64       \n",
      " 23  away_player_9     21374 non-null  float64       \n",
      " 24  away_player_10    21374 non-null  float64       \n",
      " 25  away_player_11    21374 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(22), int64(3)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Now we'll focus on preparing our table for question1\n",
    "match_columns1 = [\"date\",\"match_api_id\",\"home_team_api_id\",\"away_team_api_id\"]\n",
    "match_columns_final = match_columns1 + home_team + away_team\n",
    "df_question1 = df_match.loc[:,match_columns_final]\n",
    "df_question1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're going to get the birthday information for each home player\n",
    "for number in range(11):\n",
    "    df_question1 = df_question1.merge(df_player, left_on=\"home_player_\"+str(number+1), right_on=\"player_api_id\", how=\"left\", suffixes=(None,\"_h\"+str(number+1)))\n",
    "    df_question1.drop(\"player_api_id\", axis=1, inplace=True)\n",
    "    \n",
    "df_question1.rename(columns={\"birthday\":\"birthday_h1\",\"height\":\"height_h1\",\"weight\":\"weight_h1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now for each away player\n",
    "for number in range(11):\n",
    "    df_question1 = df_question1.merge(df_player, left_on=\"away_player_\"+str(number+1), right_on=\"player_api_id\", how=\"left\", suffixes=(None,\"_a\"+str(number+1)))\n",
    "    df_question1.drop(\"player_api_id\", axis=1, inplace=True)\n",
    "    \n",
    "df_question1.rename(columns={\"birthday\":\"birthday_a1\",\"height\":\"height_a1\",\"weight\":\"weight_a1\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_question1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now let's convert all datetime data with the respective player age. We'll first create the function that will do it\n",
    "def know_age(birthday):\n",
    "    match_date = df_copy[\"date\"]\n",
    "    return match_date.year - birthday.year -((match_date.month, match_date.day) < (match_date.month,match_date.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9a5af7d9afdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Let's apply it to home players\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"birthday_h\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mknow_age\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4354\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \"\"\"\n\u001b[1;32m-> 4356\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4358\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1090\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1093\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-9a5af7d9afdb>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Let's apply it to home players\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"birthday_h\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mknow_age\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-b68244e0b229>\u001b[0m in \u001b[0;36mknow_age\u001b[1;34m(birthday)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mknow_age\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbirthday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmatch_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_copy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatch_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbirthday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmatch_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatch_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5476\u001b[0m         ):\n\u001b[0;32m   5477\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5478\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'year'"
     ]
    }
   ],
   "source": [
    "# Let's apply it to home players\n",
    "for number in range(11):\n",
    "    df_copy[\"birthday_h\"+str(number+1)].apply(lambda x: know_age(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver isto mais tarde: https://www.dataquest.io/blog/tutorial-add-column-pandas-dataframe-based-on-if-else-condition/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. **Compute statistics** and **create visualizations** with the goal of addressing the research questions that you posed in the Introduction section. You should compute the relevant statistics throughout the analysis when an inference is made about the data. Note that at least two or more kinds of plots should be created as part of the exploration, and you must  compare and show trends in the varied visualizations. \n",
    "\n",
    "\n",
    "\n",
    "> **Tip**: - Investigate the stated question(s) from multiple angles. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables. You should explore at least three variables in relation to the primary question. This can be an exploratory relationship between three variables of interest, or looking at how two independent variables relate to a single dependent variable of interest. Lastly, you  should perform both single-variable (1d) and multiple-variable (2d) explorations.\n",
    "\n",
    "\n",
    "### Research Question 1 (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use this, and more code cells, to explore your data. Don't forget to add\n",
    "#   Markdown cells to document your observations and findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 2  (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue to explore the data to address your additional research\n",
    "#   questions. Add more headers as needed if you have more questions to\n",
    "#   investigate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "> **Tip**: Finally, summarize your findings and the results that have been performed in relation to the question(s) provided at the beginning of the analysis. Summarize the results accurately, and point out where additional research can be done or where additional information could be useful.\n",
    "\n",
    "\n",
    "> **Tip**: If you haven't done any statistical tests, do not imply any statistical conclusions. And make sure you avoid implying causation from correlation!\n",
    "\n",
    "### Limitations\n",
    "> **Tip**: Make sure that you are clear with regards to the limitations of your exploration. You should have at least 1 limitation explained clearly. \n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the rubric (found on the project submission page at the end of the lesson). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "## Submitting your Project \n",
    "\n",
    "> **Tip**: Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> **Tip**: Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> **Tip**: Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
